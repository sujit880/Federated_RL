{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from cmath import log\n",
    "import math\n",
    "import datetime\n",
    "from os import getpid\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import relearn.pies.dqn as DQN\n",
    "from relearn.explore import EXP, MEM\n",
    "from relearn.pies.utils import compare_weights\n",
    "\n",
    "import modman\n",
    "\n",
    "from queue import Queue\n",
    "import gym\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import socket   \n",
    "\n",
    "hostname = socket.gethostname()   \n",
    "IPAddr = socket.gethostbyname(hostname) \n",
    "\n",
    "\n",
    "now = datetime.datetime.now\n",
    "\n",
    "##############################################\n",
    "# SETUP Hyperparameters\n",
    "##############################################\n",
    "ALIAS = 'experiment_01'\n",
    "ENV_NAME = 'CartPole-v0'\n",
    "\n",
    "# For test locally -> ..\n",
    "# API endpoint\n",
    "URL = \"http://localhost:5500/api/model/\"  # Un comment this line if you wanna test locally\n",
    "# ..\n",
    "\n",
    "# For test in the server and sepertade clients ...\n",
    "\n",
    "ip_address = \"172.16.26.15\"  # server macine ip address\n",
    "# API endpoint\n",
    "# URL = \"http://\"+ip_address+\":5500/api/model/\"\n",
    "\n",
    "# ..\n",
    "\n",
    "class INFRA:\n",
    "    \"\"\" Dummy empty class\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "EXP_PARAMS = INFRA()\n",
    "EXP_PARAMS.MEM_CAP = 50000\n",
    "EXP_PARAMS.EPST = (0.95, 0.05, 0.95)  # (start, min, max)\n",
    "EXP_PARAMS.DECAY_MUL = 0.99999\n",
    "EXP_PARAMS.DECAY_ADD = 0\n",
    "\n",
    "\n",
    "PIE_PARAMS = INFRA()\n",
    "PIE_PARAMS.LAYERS = [128, 128, 128]\n",
    "PIE_PARAMS.OPTIM = torch.optim.RMSprop # 1. RMSprop, 2. Adam, 3. SGD\n",
    "PIE_PARAMS.LOSS = torch.nn.MSELoss\n",
    "PIE_PARAMS.LR = 0.001\n",
    "PIE_PARAMS.DISCOUNT = 0.999999\n",
    "PIE_PARAMS.DOUBLE = False\n",
    "PIE_PARAMS.TUF = 4\n",
    "PIE_PARAMS.DEV = 'cpu'\n",
    "\n",
    "TRAIN_PARAMS = INFRA()\n",
    "TRAIN_PARAMS.EPOCHS = 50000\n",
    "TRAIN_PARAMS.MOVES = 10\n",
    "TRAIN_PARAMS.EPISODIC = False\n",
    "TRAIN_PARAMS.MIN_MEM = 30\n",
    "TRAIN_PARAMS.LEARN_STEPS = 1\n",
    "TRAIN_PARAMS.BATCH_SIZE = 50\n",
    "TRAIN_PARAMS.TEST_FREQ = 10\n",
    "\n",
    "TEST_PARAMS = INFRA()\n",
    "TEST_PARAMS.CERF = 100\n",
    "TEST_PARAMS.RERF = 100\n",
    "\n",
    "\n",
    "P = print\n",
    "\n",
    "\n",
    "def F(fig, file_name): return plt.close()  # print('FIGURE ::',file_name)\n",
    "\n",
    "\n",
    "def T(header, table): return print(header, '\\n', table)\n",
    "\n",
    "\n",
    "P('#', ALIAS)\n",
    "\n",
    "##############################################\n",
    "# Setup ENVS\n",
    "##############################################\n",
    "\n",
    "# Train ENV\n",
    "env = gym.make(ENV_NAME)\n",
    "\n",
    "# Test ENV\n",
    "venv = gym.make(ENV_NAME)\n",
    "\n",
    "# Policy and Exploration\n",
    "exp = EXP(env=env, cap=EXP_PARAMS.MEM_CAP, epsilonT=EXP_PARAMS.EPST)\n",
    "\n",
    "txp = EXP(env=venv, cap=math.inf, epsilonT=(0, 0, 0))\n",
    "\n",
    "\n",
    "def decayF(epsilon, moves, isdone):\n",
    "    global eps\n",
    "    new_epsilon = epsilon*EXP_PARAMS.DECAY_MUL + \\\n",
    "        EXP_PARAMS.DECAY_ADD  # random.random()\n",
    "    eps.append(new_epsilon)\n",
    "    return new_epsilon\n",
    "\n",
    "\n",
    "pie = DQN.PIE(\n",
    "    env.observation_space.shape[0],\n",
    "    LL=PIE_PARAMS.LAYERS,\n",
    "    action_dim=env.action_space.n,\n",
    "    device=PIE_PARAMS.DEV,\n",
    "    opt=PIE_PARAMS.OPTIM,\n",
    "    cost=PIE_PARAMS.LOSS,\n",
    "    lr=PIE_PARAMS.LR,\n",
    "    dis=PIE_PARAMS.DISCOUNT,\n",
    "    mapper=lambda x: x,\n",
    "    double=PIE_PARAMS.DOUBLE,\n",
    "    tuf=PIE_PARAMS.TUF,\n",
    "    seed=None)\n",
    "\n",
    "target = DQN.PIE(\n",
    "    env.observation_space.shape[0],\n",
    "    LL=PIE_PARAMS.LAYERS,\n",
    "    action_dim=env.action_space.n,\n",
    "    device=PIE_PARAMS.DEV,\n",
    "    opt=PIE_PARAMS.OPTIM,\n",
    "    cost=PIE_PARAMS.LOSS,\n",
    "    lr=PIE_PARAMS.LR,\n",
    "    dis=PIE_PARAMS.DISCOUNT,\n",
    "    mapper=lambda x: x,\n",
    "    double=PIE_PARAMS.DOUBLE,\n",
    "    tuf=PIE_PARAMS.TUF,\n",
    "    seed=None)\n",
    "log_data=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Fetch Initial Model Params (If Available)\n",
    "##############################################\n",
    "while modman.get_model_lock(URL):  # wait if model updation is going on\n",
    "    print(\"Waiting for Model Lock Release.\")\n",
    "\n",
    "global_params, n_push, log_id, is_available = modman.fetch_params(URL+'get')\n",
    "\n",
    "n_steps=n_push\n",
    "\n",
    "log_path = './client/logs/'\n",
    "log_file = log_id+ 'client_logs.csv'\n",
    "log_testing = log_id+ 'testing_logs.csv'\n",
    "\n",
    "path1 = modman.increment_path(path=log_path+log_file,exist_ok=False,mkdir=True)\n",
    "path2 = modman.increment_path(path=log_path+log_testing,exist_ok=False,mkdir=True)\n",
    "\n",
    "modman.csv_writer(path=path1,data=[[f'Log Data for Client IPAddres: {IPAddr} Pid: {getpid()}']])\n",
    "modman.csv_writer(path=path2,data=[[f'Log Data for Client IPAddres: {IPAddr} Pid: {getpid()}']])\n",
    "if is_available:\n",
    "    P(\"Model exist\")\n",
    "    P(\"Loading Q params .....\")\n",
    "    P(\"Number Push: \", n_push)\n",
    "    log_data.append([f'Log Data for Client IPAddres: {IPAddr} Pid: {getpid()}'])\n",
    "    log_data.append([\"Model exist\"])\n",
    "    log_data.append(['Loading Q params .......'])\n",
    "    log_data.append([\"Number Push: \", n_push])\n",
    "    pie.Q.load_state_dict(modman.convert_list_to_tensor(global_params))\n",
    "    pie.Q.eval()\n",
    "    P(\"Loading T params .....\")\n",
    "    pie.T.load_state_dict(pie.Q.state_dict())\n",
    "    pie.T.eval()\n",
    "else:\n",
    "    P(\"Setting model for server\")\n",
    "    P(\"Number Push: \", n_push)\n",
    "    log_data.append([f'Log Data for Client IPAddres: {IPAddr} Pid: {getpid()}'])\n",
    "    log_data.append([\"Setting model for server\"])\n",
    "    log_data.append([\"Number Push: \", n_push])\n",
    "    reply = modman.send_model_params(\n",
    "        URL, modman.convert_tensor_to_list(pie.Q.state_dict()), PIE_PARAMS.LR)\n",
    "    print(reply)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Training\n",
    "##############################################\n",
    "P('#', 'Train')\n",
    "P('Start Training...')\n",
    "log_data.append(['Start Training...'])\n",
    "stamp = now()\n",
    "eps = []\n",
    "ref = []\n",
    "c_d1 =[] # communication delay 1\n",
    "tpc = [] # Timeime per epoch\n",
    "tft = [] # Time for testing\n",
    "L_T = [] # Learning Time\n",
    "REW = [] # Rewards list\n",
    "REW.append([f'\\n\\nTesting Data for Client IPAddres: {IPAddr} Pid: {getpid()} ..'])\n",
    "max_reward1 = Queue(maxsize=100)\n",
    "\n",
    "P('after max_reward queue')\n",
    "exp.reset(clear_mem=True, reset_epsilon=True)\n",
    "txp.reset(clear_mem=True, reset_epsilon=True)\n",
    "\n",
    "lt1=now() # setting initial learning time\n",
    "for epoch in range(0, TRAIN_PARAMS.EPOCHS):\n",
    "    stpc = now() # start time for epoch\n",
    "    lt1 +=(now()-lt1)  # time at epoch start\n",
    "    # exploration\n",
    "    _ = exp.explore(pie, moves=TRAIN_PARAMS.MOVES,\n",
    "                    decay=decayF, episodic=TRAIN_PARAMS.EPISODIC)\n",
    "\n",
    "    if exp.memory.count > TRAIN_PARAMS.MIN_MEM:\n",
    "\n",
    "        for _ in range(TRAIN_PARAMS.LEARN_STEPS):\n",
    "            # Single Learning Step\n",
    "            pie.learn(exp.memory, TRAIN_PARAMS.BATCH_SIZE)\n",
    "\n",
    "            # Send Parameters to Server\n",
    "            if (epoch+1)%n_steps==0:\n",
    "                lt2=now()\n",
    "                print(\"Learning Time: \", lt2-lt1)\n",
    "                L_T.append(lt2-lt1)\n",
    "                lt1=now() # setting new initial learning time\n",
    "                t1=now() #time stamp at the start time for communication\n",
    "\n",
    "\n",
    "\n",
    "                params = modman.convert_tensor_to_list(pie.Q.state_dict())\n",
    "                P(\"Length: \", len(params))\n",
    "                # Sending Locally Trained Params\n",
    "                reply = modman.send_local_update(URL + 'post_params',\n",
    "                 modman.convert_tensor_to_list(pie.Q.state_dict()),\n",
    "                 epoch+1)\n",
    "                print(reply)\n",
    "                log_data.append(reply)\n",
    "                \n",
    "                # Wait for Model Lock to get Released\n",
    "                while modman.get_model_lock(URL):\n",
    "                    print(\"Waiting for Model Lock Release.\")\n",
    "\n",
    "                # Get Updated Model Params from Server\n",
    "                global_params, n_push,_, is_available = modman.fetch_params(URL + 'get')\n",
    "                n_steps=n_push\n",
    "                pie.Q.load_state_dict(modman.convert_list_to_tensor(global_params))\n",
    "                pie.Q.eval()\n",
    "\n",
    "                t2=now() #time stamp at the end time of communication\n",
    "                print(\"Communication delay: \", t2-t1)\n",
    "                c_d1.append(t2-t1)\n",
    "    etpc = now() # end time for epoch\n",
    "    tpc.append(etpc-stpc)\n",
    "    stft=now() # Start time for testing\n",
    "    # P(\"after explore epoch#:\",epoch)\n",
    "    if epoch == 0 or (epoch+1) % TRAIN_PARAMS.TEST_FREQ == 0:\n",
    "        txp.reset(clear_mem=True)\n",
    "        timesteps = txp.explore(\n",
    "            pie, moves=1, decay=EXP.NO_DECAY, episodic=True)\n",
    "        res = txp.summary(P=lambda *arg: None)\n",
    "        trew = res[-1]\n",
    "        ref.append([trew])\n",
    "        #print('before queue')\n",
    "        if(max_reward1.full()):\n",
    "            max_reward1.get()\n",
    "        max_reward1.put(trew)\n",
    "        #print('after queue')\n",
    "        P('[#]'+str(epoch+1), '\\t',\n",
    "            '[REW]'+str(trew),\n",
    "            '[TR]'+str(pie.train_count),\n",
    "            '[UP]'+str(pie.update_count))\n",
    "        REW.append([\"Rew: \",trew, \"Train_count: \", pie.train_count, \"Update_count: \", pie.update_count])\n",
    "        if(max_reward1.full()):\n",
    "            if(np.mean(max_reward1.queue) >= 200):\n",
    "                break\n",
    "    etft = now() # End time for testing\n",
    "    tft.append(etft-stft)\n",
    "P('Finished Training!')\n",
    "elapse = now() - stamp\n",
    "P('Time Elapsed:', elapse)\n",
    "P('Mean Learning Time:', np.mean(L_T))\n",
    "P('MAX Learning Time:', np.max(L_T))\n",
    "P('MIN Learning Time:', np.min(L_T))\n",
    "P('Mean Communication Time:', np.mean(c_d1))\n",
    "P('MAX Communication Time:', np.max(c_d1))\n",
    "P('MIN Communication Time:', np.min(c_d1))\n",
    "P('Total Learning Time:->', np.sum(L_T))\n",
    "P('Total Communication delay:->', np.sum(c_d1))\n",
    "P('Mean time for epoch:', np.mean(tpc))\n",
    "P('MIN time for epoch:', np.min(tpc))\n",
    "P('MAX time for epoch:', np.max(tpc))\n",
    "P('Total time for epoch:->', np.sum(tpc))\n",
    "P('Total time for testing:->', np.sum(tft))\n",
    "\n",
    "# preparing log data\n",
    "log_data.append([f'\\nTotal number of epochs: {epoch}'])\n",
    "log_data.append(['\\nTime Elapsed:', elapse])\n",
    "log_data.append(['\\nMean Learning Time:', np.mean(L_T)])\n",
    "log_data.append(['MAX Learning Time:', np.max(L_T)])\n",
    "log_data.append(['MIN Learning Time:', np.min(L_T)])\n",
    "log_data.append(['\\nMean Communication Time:', np.mean(c_d1)])\n",
    "log_data.append(['MAX Communication Time:', np.max(c_d1)])\n",
    "log_data.append(['MIN Communication Time:', np.min(c_d1)])\n",
    "log_data.append(['\\nTotal Learning Time:->', np.sum(L_T)])\n",
    "log_data.append(['\\nTotal Communication delay:->', np.sum(c_d1)])\n",
    "log_data.append(['\\nMean time for epoch:', np.mean(tpc)])\n",
    "log_data.append(['MIN time for epoch:', np.min(tpc)])\n",
    "log_data.append(['MAX time for epoch:', np.max(tpc)])\n",
    "log_data.append(['\\nTotal time for epoch:->', np.sum(tpc)])\n",
    "log_data.append(['\\nTotal time for testing:->', np.sum(tft)])\n",
    "modman.csv_writer(path=path1,data=log_data)\n",
    "modman.csv_writer(path=path2,data=REW)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
